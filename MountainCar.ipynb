{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Box(2,)\n",
      "Discrete(3)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"MountainCar-v0\")\n",
    "\n",
    "print(env.observation_space)\n",
    "print(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class No_learning_Agent():\n",
    "    def __init__(self,env):\n",
    "        self.act_size = env.action_space.n\n",
    "        self.best_position = 0.5\n",
    "        print (self.act_size)\n",
    "        \n",
    "    def get_action(self,state):\n",
    "        action = random.choice(range(self.act_size))\n",
    "        position = state[0]\n",
    "        velocity = state[1]\n",
    "        if position >= -0.5 and velocity >= -0.012:\n",
    "            action = 0\n",
    "        elif position <= -0.5 and velocity <= -0.012:\n",
    "            action = 2\n",
    "            \n",
    "        return action\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "step = 1 state =  [-0.48789912 -0.00127675]  reward =  -1.0\n",
      "step = 2 state =  [-0.49044311 -0.00254399]  reward =  -1.0\n",
      "step = 3 state =  [-0.49423536 -0.00379225]  reward =  -1.0\n",
      "step = 4 state =  [-0.49924755 -0.00501219]  reward =  -1.0\n",
      "step = 5 state =  [-0.50544221 -0.00619466]  reward =  -1.0\n",
      "step = 6 state =  [-0.51277298 -0.00733077]  reward =  -1.0\n",
      "step = 7 state =  [-0.52018492 -0.00741195]  reward =  -1.0\n",
      "step = 8 state =  [-0.52762247 -0.00743755]  reward =  -1.0\n",
      "step = 9 state =  [-0.53402985 -0.00640737]  reward =  -1.0\n",
      "step = 10 state =  [-0.540359   -0.00632915]  reward =  -1.0\n",
      "step = 11 state =  [-0.54756251 -0.0072035 ]  reward =  -1.0\n",
      "step = 12 state =  [-0.55558644 -0.00802393]  reward =  -1.0\n",
      "step = 13 state =  [-0.56237083 -0.00678439]  reward =  -1.0\n",
      "step = 14 state =  [-0.56886509 -0.00649426]  reward =  -1.0\n",
      "step = 15 state =  [-0.57402089 -0.0051558 ]  reward =  -1.0\n",
      "step = 16 state =  [-0.57879996 -0.00477908]  reward =  -1.0\n",
      "step = 17 state =  [-0.58216692 -0.00336696]  reward =  -1.0\n",
      "step = 18 state =  [-0.58609687 -0.00392995]  reward =  -1.0\n",
      "step = 19 state =  [-0.59056083 -0.00446396]  reward =  -1.0\n",
      "step = 20 state =  [-0.59452595 -0.00396511]  reward =  -1.0\n",
      "step = 21 state =  [-0.59796311 -0.00343717]  reward =  -1.0\n",
      "step = 22 state =  [-0.60184716 -0.00388405]  reward =  -1.0\n",
      "step = 23 state =  [-0.60414972 -0.00230256]  reward =  -1.0\n",
      "step = 24 state =  [-0.60685401 -0.00270429]  reward =  -1.0\n",
      "step = 25 state =  [-0.60894036 -0.00208635]  reward =  -1.0\n",
      "step = 26 state =  [-0.61039362 -0.00145326]  reward =  -1.0\n",
      "step = 27 state =  [-6.10203242e-01  1.90374154e-04]  reward =  -1.0\n",
      "step = 28 state =  [-6.10370617e-01 -1.67375299e-04]  reward =  -1.0\n",
      "step = 29 state =  [-0.60889453  0.00147609]  reward =  -1.0\n",
      "step = 30 state =  [-0.60778568  0.00110885]  reward =  -1.0\n",
      "step = 31 state =  [-0.60505212  0.00273356]  reward =  -1.0\n",
      "step = 32 state =  [-0.60271373  0.0023384 ]  reward =  -1.0\n",
      "step = 33 state =  [-0.60078752  0.0019262 ]  reward =  -1.0\n",
      "step = 34 state =  [-0.59828756  0.00249996]  reward =  -1.0\n",
      "step = 35 state =  [-0.59523211  0.00305545]  reward =  -1.0\n",
      "step = 36 state =  [-0.59164354  0.00358857]  reward =  -1.0\n",
      "step = 37 state =  [-0.58754816  0.00409537]  reward =  -1.0\n",
      "step = 38 state =  [-0.58397611  0.00357206]  reward =  -1.0\n",
      "step = 39 state =  [-0.57995369  0.00402241]  reward =  -1.0\n",
      "step = 40 state =  [-0.57651063  0.00344307]  reward =  -1.0\n",
      "step = 41 state =  [-0.57167239  0.00483824]  reward =  -1.0\n",
      "step = 42 state =  [-0.56747484  0.00419754]  reward =  -1.0\n",
      "step = 43 state =  [-0.56394918  0.00352567]  reward =  -1.0\n",
      "step = 44 state =  [-0.55912162  0.00482755]  reward =  -1.0\n",
      "step = 45 state =  [-0.55302815  0.00609347]  reward =  -1.0\n",
      "step = 46 state =  [-0.54771424  0.00531391]  reward =  -1.0\n",
      "step = 47 state =  [-0.54221963  0.00549461]  reward =  -1.0\n",
      "step = 48 state =  [-0.53658543  0.0056342 ]  reward =  -1.0\n",
      "step = 49 state =  [-0.52985386  0.00673157]  reward =  -1.0\n",
      "step = 50 state =  [-0.52207538  0.00777848]  reward =  -1.0\n",
      "step = 51 state =  [-0.51430832  0.00776706]  reward =  -1.0\n",
      "step = 52 state =  [-0.50661093  0.00769739]  reward =  -1.0\n",
      "step = 53 state =  [-0.4980409   0.00857003]  reward =  -1.0\n",
      "step = 54 state =  [-0.49066236  0.00737854]  reward =  -1.0\n",
      "step = 55 state =  [-0.48453044  0.00613192]  reward =  -1.0\n",
      "step = 56 state =  [-0.47969087  0.00483957]  reward =  -1.0\n",
      "step = 57 state =  [-0.47617965  0.00351122]  reward =  -1.0\n",
      "step = 58 state =  [-0.47402288  0.00215677]  reward =  -1.0\n",
      "step = 59 state =  [-0.47323655  0.00078632]  reward =  -1.0\n",
      "step = 60 state =  [-0.47382651 -0.00058996]  reward =  -1.0\n",
      "step = 61 state =  [-0.47578838 -0.00196187]  reward =  -1.0\n",
      "step = 62 state =  [-0.4791076  -0.00331922]  reward =  -1.0\n",
      "step = 63 state =  [-0.4837595  -0.00465191]  reward =  -1.0\n",
      "step = 64 state =  [-0.4897095  -0.00594999]  reward =  -1.0\n",
      "step = 65 state =  [-0.49691322 -0.00720373]  reward =  -1.0\n",
      "step = 66 state =  [-0.50531688 -0.00840365]  reward =  -1.0\n",
      "step = 67 state =  [-0.51485757 -0.0095407 ]  reward =  -1.0\n",
      "step = 68 state =  [-0.52446382 -0.00960625]  reward =  -1.0\n",
      "step = 69 state =  [-0.53306359 -0.00859976]  reward =  -1.0\n",
      "step = 70 state =  [-0.54059237 -0.00752879]  reward =  -1.0\n",
      "step = 71 state =  [-0.54799376 -0.00740139]  reward =  -1.0\n",
      "step = 72 state =  [-0.55621235 -0.00821859]  reward =  -1.0\n",
      "step = 73 state =  [-0.56318673 -0.00697438]  reward =  -1.0\n",
      "step = 74 state =  [-0.56986489 -0.00667817]  reward =  -1.0\n",
      "step = 75 state =  [-0.57619718 -0.00633228]  reward =  -1.0\n",
      "step = 76 state =  [-0.58313661 -0.00693943]  reward =  -1.0\n",
      "step = 77 state =  [-0.58963187 -0.00649527]  reward =  -1.0\n",
      "step = 78 state =  [-0.59463513 -0.00500325]  reward =  -1.0\n",
      "step = 79 state =  [-0.59910963 -0.0044745 ]  reward =  -1.0\n",
      "step = 80 state =  [-0.60402263 -0.004913  ]  reward =  -1.0\n",
      "step = 81 state =  [-0.60733829 -0.00331566]  reward =  -1.0\n",
      "step = 82 state =  [-0.60903249 -0.0016942 ]  reward =  -1.0\n",
      "step = 83 state =  [-0.61009292 -0.00106044]  reward =  -1.0\n",
      "step = 84 state =  [-6.09511908e-01  5.81014237e-04]  reward =  -1.0\n",
      "step = 85 state =  [-0.60829366  0.00121825]  reward =  -1.0\n",
      "step = 86 state =  [-0.605447    0.00284665]  reward =  -1.0\n",
      "step = 87 state =  [-0.60199264  0.00345436]  reward =  -1.0\n",
      "step = 88 state =  [-0.59895573  0.00303691]  reward =  -1.0\n",
      "step = 89 state =  [-0.59435844  0.00459729]  reward =  -1.0\n",
      "step = 90 state =  [-0.59023443  0.00412401]  reward =  -1.0\n",
      "step = 91 state =  [-0.58661398  0.00362045]  reward =  -1.0\n",
      "step = 92 state =  [-0.58152372  0.00509026]  reward =  -1.0\n",
      "step = 93 state =  [-0.57500121  0.00652251]  reward =  -1.0\n",
      "step = 94 state =  [-0.56909471  0.0059065 ]  reward =  -1.0\n",
      "step = 95 state =  [-0.56184804  0.00724666]  reward =  -1.0\n",
      "step = 96 state =  [-0.55331514  0.0085329 ]  reward =  -1.0\n",
      "step = 97 state =  [-0.54555966  0.00775548]  reward =  -1.0\n",
      "step = 98 state =  [-0.53863959  0.00692007]  reward =  -1.0\n",
      "step = 99 state =  [-0.53260675  0.00603284]  reward =  -1.0\n",
      "step = 100 state =  [-0.52750636  0.00510039]  reward =  -1.0\n",
      "step = 101 state =  [-0.52337666  0.0041297 ]  reward =  -1.0\n",
      "step = 102 state =  [-0.51824863  0.00512803]  reward =  -1.0\n",
      "step = 103 state =  [-0.51216073  0.00608791]  reward =  -1.0\n",
      "step = 104 state =  [-0.50715859  0.00500214]  reward =  -1.0\n",
      "step = 105 state =  [-0.50227971  0.00487889]  reward =  -1.0\n",
      "step = 106 state =  [-0.4965606  0.0057191]  reward =  -1.0\n",
      "step = 107 state =  [-0.49204407  0.00451654]  reward =  -1.0\n",
      "step = 108 state =  [-0.48876384  0.00328023]  reward =  -1.0\n",
      "step = 109 state =  [-0.48674439  0.00201944]  reward =  -1.0\n",
      "step = 110 state =  [-0.48600079  0.0007436 ]  reward =  -1.0\n",
      "step = 111 state =  [-0.48653858 -0.00053779]  reward =  -1.0\n",
      "step = 112 state =  [-0.48835375 -0.00181517]  reward =  -1.0\n",
      "step = 113 state =  [-0.49143276 -0.00307901]  reward =  -1.0\n",
      "step = 114 state =  [-0.49575265 -0.00431988]  reward =  -1.0\n",
      "step = 115 state =  [-0.50128114 -0.00552849]  reward =  -1.0\n",
      "step = 116 state =  [-0.50797688 -0.00669574]  reward =  -1.0\n",
      "step = 117 state =  [-0.51578975 -0.00781287]  reward =  -1.0\n",
      "step = 118 state =  [-0.52366117 -0.00787143]  reward =  -1.0\n",
      "step = 119 state =  [-0.53153213 -0.00787096]  reward =  -1.0\n",
      "step = 120 state =  [-0.5383436  -0.00681147]  reward =  -1.0\n",
      "step = 121 state =  [-0.54404452 -0.00570092]  reward =  -1.0\n",
      "step = 122 state =  [-0.54859218 -0.00454767]  reward =  -1.0\n",
      "step = 123 state =  [-0.55195258 -0.00336039]  reward =  -1.0\n",
      "step = 124 state =  [-0.55510057 -0.003148  ]  reward =  -1.0\n",
      "step = 125 state =  [-0.55801266 -0.00291208]  reward =  -1.0\n",
      "step = 126 state =  [-0.5606671  -0.00265444]  reward =  -1.0\n",
      "step = 127 state =  [-0.5620441 -0.001377 ]  reward =  -1.0\n",
      "step = 128 state =  [-0.56313339 -0.0010893 ]  reward =  -1.0\n",
      "step = 129 state =  [-5.62926877e-01  2.06517123e-04]  reward =  -1.0\n",
      "step = 130 state =  [-0.56142608  0.00150079]  reward =  -1.0\n",
      "step = 131 state =  [-0.55964219  0.00178389]  reward =  -1.0\n",
      "step = 132 state =  [-0.5565885   0.00305369]  reward =  -1.0\n",
      "step = 133 state =  [-0.55328779  0.00330071]  reward =  -1.0\n",
      "step = 134 state =  [-0.55076471  0.00252308]  reward =  -1.0\n",
      "step = 135 state =  [-0.54803811  0.0027266 ]  reward =  -1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 136 state =  [-0.54512838  0.00290973]  reward =  -1.0\n",
      "step = 137 state =  [-0.54305729  0.00207109]  reward =  -1.0\n",
      "step = 138 state =  [-0.53984034  0.00321695]  reward =  -1.0\n",
      "step = 139 state =  [-0.53650163  0.00333871]  reward =  -1.0\n",
      "step = 140 state =  [-0.53306617  0.00343546]  reward =  -1.0\n",
      "step = 141 state =  [-0.52855972  0.00450645]  reward =  -1.0\n",
      "step = 142 state =  [-0.52501606  0.00354366]  reward =  -1.0\n",
      "step = 143 state =  [-0.52146177  0.00355429]  reward =  -1.0\n",
      "step = 144 state =  [-0.5179235   0.00353826]  reward =  -1.0\n",
      "step = 145 state =  [-0.5134278  0.0044957]  reward =  -1.0\n",
      "step = 146 state =  [-0.50900837  0.00441943]  reward =  -1.0\n",
      "step = 147 state =  [-0.50569834  0.00331004]  reward =  -1.0\n",
      "step = 148 state =  [-0.50152249  0.00417585]  reward =  -1.0\n",
      "step = 149 state =  [-0.4965121  0.0050104]  reward =  -1.0\n",
      "step = 150 state =  [-0.49270463  0.00380747]  reward =  -1.0\n",
      "step = 151 state =  [-0.49012853  0.0025761 ]  reward =  -1.0\n",
      "step = 152 state =  [-0.48880304  0.00132549]  reward =  -1.0\n",
      "step = 153 state =  [-4.88738045e-01  6.49955958e-05]  reward =  -1.0\n",
      "step = 154 state =  [-0.48993403 -0.00119598]  reward =  -1.0\n",
      "step = 155 state =  [-0.49238207 -0.00244804]  reward =  -1.0\n",
      "step = 156 state =  [-0.49606389 -0.00368182]  reward =  -1.0\n",
      "step = 157 state =  [-0.50095199 -0.0048881 ]  reward =  -1.0\n",
      "step = 158 state =  [-0.50700981 -0.00605782]  reward =  -1.0\n",
      "step = 159 state =  [-0.513192   -0.00618219]  reward =  -1.0\n",
      "step = 160 state =  [-0.51845222 -0.00526022]  reward =  -1.0\n",
      "step = 161 state =  [-0.52475105 -0.00629882]  reward =  -1.0\n",
      "step = 162 state =  [-0.53004123 -0.00529018]  reward =  -1.0\n",
      "step = 163 state =  [-0.53528309 -0.00524186]  reward =  -1.0\n",
      "step = 164 state =  [-0.53943734 -0.00415425]  reward =  -1.0\n",
      "step = 165 state =  [-0.54247285 -0.00303551]  reward =  -1.0\n",
      "step = 166 state =  [-0.54636687 -0.00389403]  reward =  -1.0\n",
      "step = 167 state =  [-0.55109027 -0.0047234 ]  reward =  -1.0\n",
      "step = 168 state =  [-0.55660772 -0.00551745]  reward =  -1.0\n",
      "step = 169 state =  [-0.561878   -0.00527028]  reward =  -1.0\n",
      "step = 170 state =  [-0.56586182 -0.00398382]  reward =  -1.0\n",
      "step = 171 state =  [-0.56852951 -0.00266769]  reward =  -1.0\n",
      "step = 172 state =  [-0.57186125 -0.00333173]  reward =  -1.0\n",
      "step = 173 state =  [-0.57383227 -0.00197103]  reward =  -1.0\n",
      "step = 174 state =  [-0.57542798 -0.0015957 ]  reward =  -1.0\n",
      "step = 175 state =  [-5.75636524e-01 -2.08547302e-04]  reward =  -1.0\n",
      "step = 176 state =  [-0.57645637 -0.00081985]  reward =  -1.0\n",
      "step = 177 state =  [-0.57788145 -0.00142507]  reward =  -1.0\n",
      "step = 178 state =  [-0.5789012  -0.00101975]  reward =  -1.0\n",
      "step = 179 state =  [-5.78508082e-01  3.93116110e-04]  reward =  -1.0\n",
      "step = 180 state =  [-0.57670501  0.00180308]  reward =  -1.0\n",
      "step = 181 state =  [-0.57350532  0.00319969]  reward =  -1.0\n",
      "step = 182 state =  [-0.56993272  0.00357259]  reward =  -1.0\n",
      "step = 183 state =  [-0.56701375  0.00291898]  reward =  -1.0\n",
      "step = 184 state =  [-0.56277007  0.00424367]  reward =  -1.0\n",
      "step = 185 state =  [-0.55823329  0.00453678]  reward =  -1.0\n",
      "step = 186 state =  [-0.55343722  0.00479607]  reward =  -1.0\n",
      "step = 187 state =  [-0.54741766  0.00601956]  reward =  -1.0\n",
      "step = 188 state =  [-0.54121961  0.00619805]  reward =  -1.0\n",
      "step = 189 state =  [-0.53488946  0.00633015]  reward =  -1.0\n",
      "step = 190 state =  [-0.52747465  0.00741481]  reward =  -1.0\n",
      "step = 191 state =  [-0.52103077  0.00644388]  reward =  -1.0\n",
      "step = 192 state =  [-0.51560616  0.00542462]  reward =  -1.0\n",
      "step = 193 state =  [-0.50924148  0.00636468]  reward =  -1.0\n",
      "step = 194 state =  [-0.50398444  0.00525703]  reward =  -1.0\n",
      "step = 195 state =  [-0.49987443  0.00411001]  reward =  -1.0\n",
      "step = 196 state =  [-0.4969422   0.00293223]  reward =  -1.0\n",
      "step = 197 state =  [-0.49520969  0.00173252]  reward =  -1.0\n",
      "step = 198 state =  [-0.49468983  0.00051986]  reward =  -1.0\n",
      "step = 199 state =  [-0.49538652 -0.00069669]  reward =  -1.0\n",
      "step = 200 state =  [-0.49729455 -0.00190803]  reward =  -1.0\n"
     ]
    }
   ],
   "source": [
    "agent = No_learning_Agent(env)\n",
    "state = env.reset()\n",
    "for i in range(1,201):\n",
    "    action = agent.get_action(state)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    print(\"step =\",i,\"state = \",state,\" reward = \",reward)\n",
    "    env.render()\n",
    "    time.sleep(0.05)\n",
    "    if done:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py36)",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
